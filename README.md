# 📘 Insightify

Insightify is an AI-powered tool that enables users to upload a research document (PDF or TXT) and interact with it intelligently — by asking questions, receiving logic-based challenges, and getting evaluated on their understanding.

## 🚀 Features

🔍 Document-Aware Understanding
Upload PDF or TXT documents and let Insightify analyze their content for reasoning and summarization.

🧠 Ask Anything
Ask free-form questions. Get answers grounded in the actual document with justification.

🎯 Challenge Me Mode
Insightify generates logic-based questions based on your document and evaluates your answers with reasoning.

📝 Instant Auto Summary
Receive a concise ≤150-word summary right after uploading your document.

🧾 Justified Answers
Each answer includes a reference (e.g., “as stated in section 2…”) to ensure transparency and trust.

---

## ⚙️ Tech Stack

| Component      | Technology               |
| -------------- | ------------------------ |
| Backend API    | FastAPI                  |
| Frontend UI    | Streamlit                |
| Embeddings     | Gemini 2.5 Embedding API |
| LLM Reasoning  | Gemini 2.5 Pro API       |
| Vector DB      | FAISS                    |
| Chunking Logic | LangChain                |
| PDF Parsing    | PyMuPDF                  |

---

## 🏗️ Architecture

1. 🆙 Upload

* User uploads a `.pdf` or `.txt` file via the frontend.
* Text is extracted (PyMuPDF for PDFs, plain read for TXT).
* Text is split into overlapping chunks using LangChain’s `RecursiveCharacterTextSplitter`.

2. 🔎 Embedding + Indexing

* Each chunk is embedded using Gemini 2.5 Embedding API.
* FAISS stores the vector index locally.
* Original chunks are saved in a .pkl metadata file.

3. 📄 Summarization

* Gemini 2.5 Pro is used to summarize the entire document.
* Summary is returned to frontend.

4. ❓ Ask Anything

* User enters a free-form question.
* Top relevant chunks are retrieved from FAISS using similarity search.
* Retrieved context + question is sent to Gemini 2.5 Pro for answer generation.

5. 🧠 Challenge Me

* Gemini 2.5 Pro generates 3 inference-heavy logic questions from the document.
* User inputs answers, which are then evaluated:

  * Gemini generates ideal answers
  * Compares with user's answers
  * Assigns score (1–5) and gives feedback

---

## 💻 How to Use

### 1. Clone the Repo & Start Backend

```bash
git clone https://github.com/kartikeyp011/Insightify.git
cd Insightify/backend
python -m venv myenv
myenv\Scripts\activate        # or source myenv/bin/activate
pip install -r requirements.txt
```

➕ Create a `.env` file in backend with:

```
GEMINI_KEY=your_gemini_api_key
```

🟢 Start backend server:

```bash
uvicorn backend.main:app --reload
```

---

### 2. Start Frontend

```bash
cd ../frontend
streamlit run app.py
```

---

### 3. Interact from the Browser

* Upload a document → Get Summary
* Ask questions → Get answers
* Challenge Me → Get 3 reasoning questions and feedback

---

## 🧪 Sample Usage

1. Open the Streamlit interface.
2. Upload a PDF or TXT file.
3. View auto-summary.
4. Choose:

   * Ask Anything: Enter questions based on document.
   * Challenge Me: Answer logic-based questions generated by Insightify.
5. Review answers with references to the document.

---

## 🧪 Example Use Cases

* Academic paper comprehension
* Literary analysis
* Critical reasoning training
* Self-evaluation for study
* Research note summarization

---

## 📌 Start Commands Summary

Backend:

```bash
uvicorn backend.main:app --reload
```

Frontend:

```bash
streamlit run frontend/app.py
```

---

✔️ Gemini API Key: Available via Google AI Studio (free quota for Gemini 2.5 Pro and embedding).

🧠 Designed for learning, reasoning, and intelligent interaction with research content.

---

## 🧑‍⚖️ License

MIT License. See LICENSE file for details.

---

## 📬 Contact

Created by Kartikey Narain Prajapati
Email: [kartikeyp011@gmail.com](mailto:kartikeyp011@gmail.com)
GitHub: github.com/kartikeyp011
LinkedIn: linkedin.com/in/kartikeyp011/

---